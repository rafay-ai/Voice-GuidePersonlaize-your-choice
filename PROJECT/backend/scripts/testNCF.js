// Save as: backend/scripts/testNCF.js
// Comprehensive Neural Collaborative Filtering Setup Test

const mongoose = require('mongoose');
const User = require('../models/User');
const Restaurant = require('../models/Restaurant');
const Order = require('../models/Order');

async function testNCFSetup() {
    console.log('ğŸ§ª Testing Neural Collaborative Filtering Setup...');
    console.log('ğŸ“š Preparing for Phase 2: True Neural Implementation\n');
    
    try {
        // Step 1: Database Connection
        console.log('ğŸ”— Connecting to MongoDB...');
        await mongoose.connect('mongodb://localhost:27017/food-delivery');
        console.log('âœ… MongoDB connected successfully\n');
        
        // Step 2: Data Availability Check
        console.log('ğŸ“Š Analyzing Available Data:');
        const userCount = await User.countDocuments();
        const restaurantCount = await Restaurant.countDocuments();
        const orderCount = await Order.countDocuments();
        
        console.log(`   ğŸ‘¥ Users: ${userCount}`);
        console.log(`   ğŸª Restaurants: ${restaurantCount}`);
        console.log(`   ğŸ“¦ Orders: ${orderCount}`);
        
        if (userCount === 0 || restaurantCount === 0) {
            console.log('\nâŒ CRITICAL: No users or restaurants found!');
            console.log('ğŸ”§ Run this first: node scripts/seedPakistaniFood.js');
            await mongoose.connection.close();
            return;
        }
        
        // Step 3: TensorFlow.js Check
        console.log('\nğŸ§  Testing TensorFlow.js Integration:');
        let tensorflowWorking = false;
        try {
            const tf = require('@tensorflow/tfjs');
            console.log('âœ… TensorFlow.js imported successfully');
            console.log(`   ğŸ“Š Version: ${tf.version.tfjs || tf.version}`);
            
            // Test basic operations
            const testTensor = tf.tensor1d([1, 2, 3, 4]);
            const testResult = testTensor.add(1);
            console.log('âœ… Basic tensor operations working');
            
            // Test embedding (crucial for NCF)
            const embedding = tf.layers.embedding({
                inputDim: 10,
                outputDim: 4
            });
            console.log('âœ… Embedding layers functional');
            
            // Cleanup
            testTensor.dispose();
            testResult.dispose();
            tensorflowWorking = true;
            
        } catch (tfError) {
            console.log('âŒ TensorFlow.js not available:', tfError.message);
            console.log('ğŸ”§ Install with: npm install @tensorflow/tfjs');
        }
        
        // Step 4: Interaction Data Analysis
        console.log('\nğŸ”— Analyzing User-Restaurant Interactions:');
        
        const orders = await Order.find({})
            .populate('user', '_id name')
            .populate('restaurant', '_id name')
            .lean();
        
        // Calculate unique interactions
        const interactions = new Set();
        const userRestaurantPairs = new Map();
        let validOrders = 0;
        
        orders.forEach(order => {
            if (order.user && order.restaurant) {
                const userRestKey = `${order.user._id}_${order.restaurant._id}`;
                interactions.add(userRestKey);
                
                // Track frequency
                if (!userRestaurantPairs.has(userRestKey)) {
                    userRestaurantPairs.set(userRestKey, {
                        user: order.user,
                        restaurant: order.restaurant,
                        count: 0
                    });
                }
                userRestaurantPairs.get(userRestKey).count++;
                validOrders++;
            }
        });
        
        const uniqueInteractions = interactions.size;
        const sparsity = 1 - (uniqueInteractions / (userCount * restaurantCount));
        
        console.log(`   ğŸ“ˆ Total valid orders: ${validOrders}`);
        console.log(`   ğŸ”— Unique user-restaurant interactions: ${uniqueInteractions}`);
        console.log(`   ğŸ“Š Data sparsity: ${(sparsity * 100).toFixed(2)}%`);
        
        // Step 5: Data Quality Assessment
        console.log('\nğŸ“‹ Data Quality Assessment:');
        
        // Users with orders
        const usersWithOrders = new Set(orders.map(o => o.user?._id.toString())).size;
        console.log(`   ğŸ‘¥ Users with orders: ${usersWithOrders}/${userCount} (${((usersWithOrders/userCount)*100).toFixed(1)}%)`);
        
        // Restaurants with orders
        const restaurantsWithOrders = new Set(orders.map(o => o.restaurant?._id.toString())).size;
        console.log(`   ğŸª Restaurants with orders: ${restaurantsWithOrders}/${restaurantCount} (${((restaurantsWithOrders/restaurantCount)*100).toFixed(1)}%)`);
        
        // Show interaction distribution
        const interactionCounts = Array.from(userRestaurantPairs.values()).map(pair => pair.count);
        const avgInteractions = interactionCounts.reduce((a, b) => a + b, 0) / interactionCounts.length;
        const maxInteractions = Math.max(...interactionCounts);
        
        console.log(`   ğŸ“Š Avg interactions per pair: ${avgInteractions.toFixed(2)}`);
        console.log(`   ğŸ“Š Max interactions per pair: ${maxInteractions}`);
        
        // Step 6: Neural Readiness Assessment
        console.log('\nğŸ¯ Neural Training Readiness:');
        
        const requirements = {
            minUsers: 5,
            minRestaurants: 3,
            minOrders: 15,
            minInteractions: 10,
            hasTensorFlow: tensorflowWorking
        };
        
        const assessment = {
            users: userCount >= requirements.minUsers,
            restaurants: restaurantCount >= requirements.minRestaurants,
            orders: orderCount >= requirements.minOrders,
            interactions: uniqueInteractions >= requirements.minInteractions,
            tensorflow: requirements.hasTensorFlow
        };
        
        console.log(`   ğŸ‘¥ Users (â‰¥${requirements.minUsers}): ${userCount} ${assessment.users ? 'âœ…' : 'âŒ'}`);
        console.log(`   ğŸª Restaurants (â‰¥${requirements.minRestaurants}): ${restaurantCount} ${assessment.restaurants ? 'âœ…' : 'âŒ'}`);
        console.log(`   ğŸ“¦ Orders (â‰¥${requirements.minOrders}): ${orderCount} ${assessment.orders ? 'âœ…' : 'âŒ'}`);
        console.log(`   ğŸ”— Interactions (â‰¥${requirements.minInteractions}): ${uniqueInteractions} ${assessment.interactions ? 'âœ…' : 'âŒ'}`);
        console.log(`   ğŸ§  TensorFlow.js: ${assessment.tensorflow ? 'âœ…' : 'âŒ'}`);
        
        const allReady = Object.values(assessment).every(x => x);
        
        // Step 7: Recommendations
        console.log('\nğŸ“‹ RECOMMENDATIONS:');
        
        if (allReady) {
            console.log('ğŸ‰ SYSTEM READY FOR NEURAL TRAINING!');
            console.log('\nğŸš€ Next Steps:');
            console.log('   1. Create enhanced neural service');
            console.log('   2. Run: node scripts/trainNeuralModel.js');
            console.log('   3. Evaluate model performance');
            console.log('   4. Document results for FYP');
            
        } else {
            console.log('âš ï¸ System needs preparation before neural training:');
            
            if (!assessment.tensorflow) {
                console.log('   ğŸ§  Install TensorFlow.js: npm install @tensorflow/tfjs');
            }
            
            if (!assessment.interactions || !assessment.orders) {
                console.log('   ğŸ“Š Create more sample data: node scripts/createSampleOrders.js');
            }
            
            if (!assessment.users || !assessment.restaurants) {
                console.log('   ğŸŒ± Seed database: node scripts/seedPakistaniFood.js');
            }
        }
        
        // Step 8: Sample Data Preview
        if (uniqueInteractions > 0) {
            console.log('\nğŸ“ Sample Interaction Data:');
            const samplePairs = Array.from(userRestaurantPairs.values()).slice(0, 5);
            samplePairs.forEach((pair, idx) => {
                console.log(`   ${idx + 1}. ${pair.user.name} â†” ${pair.restaurant.name} (${pair.count} orders)`);
            });
        }
        
        // Step 9: Research Context
        console.log('\nğŸ“ FYP Research Context:');
        console.log('   ğŸ“š Implementing: Neural Collaborative Filtering (He et al. 2017)');
        console.log('   ğŸ›ï¸ Domain: Pakistani Food Delivery Recommendations');
        console.log('   ğŸ”¬ Research Questions:');
        console.log('      â€¢ How effective is NCF on sparse Pakistani food data?');
        console.log('      â€¢ Can neural models capture cultural preferences?');
        console.log('      â€¢ What\'s the optimal embedding dimension?');
        console.log('      â€¢ How to handle cold-start in emerging markets?');
        
        console.log('\nâœ… NCF Setup Analysis Complete!');
        
    } catch (error) {
        console.error('\nâŒ Setup analysis failed:', error);
        console.error('Full error:', error.stack);
        
        console.log('\nğŸ”§ Common Solutions:');
        console.log('   â€¢ Check MongoDB connection: mongosh');
        console.log('   â€¢ Verify Node.js version: node --version');
        console.log('   â€¢ Reinstall dependencies: npm install');
        
    } finally {
        await mongoose.connection.close();
        console.log('\nğŸ‘‹ Database connection closed');
    }
}

// Helper function to display system info
function displaySystemInfo() {
    console.log('ğŸ’» System Information:');
    console.log(`   Node.js: ${process.version}`);
    console.log(`   Platform: ${process.platform}`);
    console.log(`   Architecture: ${process.arch}`);
    console.log('');
}

// Run the test
if (require.main === module) {
    displaySystemInfo();
    testNCFSetup();
}

module.exports = { testNCFSetup };